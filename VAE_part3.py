# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X2qYjEbYY898WTuigg2IplaQEyfPnrI4
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile

zip_file_path = '/content/drive/MyDrive/COMP3710/keras_png_slices_data.zip'

# 指定解压目标文件夹的路径
extract_folder = '/content/drive/MyDrive/COMP3710/data2'  # 你可以根据需要修改目标文件夹的名称

# 打开ZIP文件并解压到指定目录
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

!pip install tensorflow

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from PIL import Image
import numpy as np

def load_data(data_dir):
    images = []
    for filename in os.listdir(data_dir):
        img_path = os.path.join(data_dir, filename)
        img = Image.open(img_path).convert('L')
        img_array = np.asarray(img).astype(np.float32) / 255.
        images.append(img_array)
    return np.array(images)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
x_train = torch.tensor(load_data('/content/drive/MyDrive/COMP3710/data2/keras_png_slices_data/keras_png_slices_train')).unsqueeze(1)
x_val = torch.tensor(load_data('/content/drive/MyDrive/COMP3710/data2/keras_png_slices_data/keras_png_slices_validate')).unsqueeze(1)


train_db = torch.utils.data.DataLoader(x_train, batch_size=512, shuffle=True)
val_db = torch.utils.data.DataLoader(x_val, batch_size=512)

import torch.nn as nn
import torch.nn.functional as F

class ConvVAE(nn.Module):
    def __init__(self):
        super(ConvVAE, self).__init__()

        # Encoder layers
        self.enc1 = nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1) # Output size: 128x128
        self.enc2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1) # Output size: 64x64
        self.enc3 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1) # Output size: 32x32
        self.enc4 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1) # Output size: 16x16

        # Latent layers
        self.fc_mean = nn.Linear(256*16*16, 512)
        self.fc_logvar = nn.Linear(256*16*16, 512)

        # Decoder layers
        self.dec1 = nn.Linear(512, 256*16*16)
        self.deconv2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)
        self.deconv3 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)
        self.deconv4 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)
        self.deconv5 = nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1)

    def encode(self, x):
        x = F.relu(self.enc1(x))
        x = F.relu(self.enc2(x))
        x = F.relu(self.enc3(x))
        x = F.relu(self.enc4(x))

        x = x.view(x.size(0), -1) # Flatten the tensor
        mean = self.fc_mean(x)
        logvar = self.fc_logvar(x)
        return mean, logvar

    def reparameterize(self, mean, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mean + eps * std

    def decode(self, z):
        x = F.relu(self.dec1(z))
        x = x.view(x.size(0), 256, 16, 16) # Reshape tensor before feeding to transposed conv layers
        x = F.relu(self.deconv2(x))
        x = F.relu(self.deconv3(x))
        x = F.relu(self.deconv4(x))
        x = torch.sigmoid(self.deconv5(x)) # Using sigmoid to ensure output values are in [0,1]
        return x

    def forward(self, x):
        mean, logvar = self.encode(x)
        z = self.reparameterize(mean, logvar)
        return self.decode(z), mean, logvar

model = ConvVAE().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)

def loss_function(recon_x, x, mu, log_var):
    BCE = F.binary_cross_entropy(recon_x.view(-1, 65536), x.view(-1, 65536), reduction='sum')
    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())
    return BCE + KLD

for epoch in range(100):
    model.train()
    train_loss = 0
    for batch_idx, data in enumerate(train_db):
        optimizer.zero_grad()
        data = data.to(device)
        recon_batch, mu, log_var = model(data)
        #print(torch.min(recon_batch), torch.max(recon_batch))
        loss = loss_function(recon_batch, data, mu, log_var)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)
        train_loss += loss.item()
        optimizer.step()
        if batch_idx % 10 == 0:
            print(f'Epoch {epoch} [{batch_idx*len(data)}/{len(train_db.dataset)}]\tLoss: {loss.item()/len(data):.6f}')


    model.eval()
    test_loss = 0
    with torch.no_grad():
        for batch_idx, data in enumerate(val_db):
            data = data.to(device)
            recon_batch, mu, log_var = model(data)
            loss = loss_function(recon_batch, data, mu, log_var)
            test_loss += loss.item()
            if batch_idx % 10 == 0:
                print(
                    f'Epoch {epoch} [{batch_idx * len(data)}/{len(val_db.dataset)}]\tLoss: {loss.item() / len(data):.6f}')
    print(f'====> Epoch: {epoch} Average loss: {train_loss / len(train_db.dataset):.4f}')
    print(f'====> Epoch: {epoch} Average loss: {test_loss / len(val_db.dataset):.4f}')

def save_reconstructed_image(img, save_dir, original_name):

    img = (img * 255).cpu().detach().numpy().astype(np.uint8).squeeze()
    img = Image.fromarray(img, mode='L')
    save_path = os.path.join(save_dir, f"reconstructed_{original_name}")
    img.save(save_path)

testpath = "/content/drive/MyDrive/COMP3710/data2/keras_png_slices_data/keras_png_slices_test"
model.eval()
with torch.no_grad():
    for image_name in os.listdir("/content/drive/MyDrive/COMP3710/data2/keras_png_slices_data/keras_png_slices_test"):
        image_path = testpath+ os.sep + image_name
        img = Image.open(image_path).convert('L')
        img_array = np.asarray(img).astype(np.float32) / 255.
        x_test = torch.tensor(img_array).unsqueeze(0).reshape(-1,1,256,256)
        x_test = x_test.to(device)
        recon_img, _, _ = model(x_test)
        save_dir = "/content/drive/MyDrive/COMP3710/predict1"
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
        save_reconstructed_image(recon_img, save_dir, image_name)

#download predict
!zip -r /content/drive/MyDrive/COMP3710/predict1.zip /content/drive/MyDrive/COMP3710/predict1

'''
data_dir = "/content/drive/MyDrive/COMP3710/data/keras_png_slices_data"
batch_size = 32

train_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
    os.path.join(data_dir, '/content/drive/MyDrive/COMP3710/data/keras_png_slices_data/keras_png_slices_train'),
    target_size=(176, 208),
    color_mode="grayscale",
    batch_size=batch_size,
    class_mode=None,  # VAE没有标签
    shuffle=True)

validation_datagen = ImageDataGenerator(rescale=1./255)
validation_generator = validation_datagen.flow_from_directory(
    os.path.join(data_dir, '/content/drive/MyDrive/COMP3710/data/keras_png_slices_data/keras_png_slices_validate'),
    target_size=(176, 208),
    color_mode="grayscale",
    batch_size=batch_size,
    class_mode=None,
    shuffle=False)